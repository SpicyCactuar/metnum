"¿Qu\'e equipo/qui\'en crees que gana hoy?", una simple pregunta que es dif\'icil de responder con certeza dada la cantidad de aspectos que ofrecen los deportes en general. Antes de analizar una manera de responder la misma con datos y fundamentos te\'oricos, abocamos en algunos casos en los cuáles esto ser\'ia \'util:

\begin{itemize}
\item \textbf{Inversiones:} Convencer de que fortalecer financieramente a una entidad/un jugador es seguro.
\item \textbf{Puntuaci\'on:} En determinados deportes o contextos, vencer a distintos oponentes no siempre genera la misma cantidad de puntos. Esto ayuda a determinar una valuaci\'on de los mismos.
\item \textbf{Medici\'on:} Podr\'ia aportar m\'etricas internas para determinar c\'omo se encuentra la entidad/el jugador comparativamente con los dem\'as.
\end{itemize}

Proveer metodolog\'ias que incorporen aspectos varios y relevantes de los encuentros es esencial para que incremente su precisión. Dicho esto, el m\'etodo que analizaremos es el \textbf{\textit{Colley Matrix Method}} \textbf{[1]}.

\subsection{Colley Matrix Method}

Este m\'etodo busca categorizar en un \textit{ranking} de \textit{ratings} a los equipos participantes, teniendo en consideraci\'on el schedule que atraves\'o cada uno de ellos, sin importar la diferencia de la cantidad de partidos jugados por cada equipo y solo considerando si el equipo gan\'o o perdi\'o  y no la diferencia en puntajes obtenidos en los mismos. Es necesario notar que s\'olo aplica a modelos de competencias que no admiten empate como un resultado posible. \\

Definamos primero el modelo utilizado para el problema. Sea $\Gamma = \{1,2,...,T\}$ el conjunto de participantes de la competencia. Luego, para cada equipo \bm{$i \in \Gamma$} denominamos \bm{$n{_i}$} al n\'umero total de partidos jugados por el equipo $i$, \bm{$w{_i}$} al n\'umero de partidos ganados por el equipo $i$ y, an\'alogamente, \bm{$l{_i}$} a la cantidad de encuentros por el equipo $i$. Por \'ultimo, dados $i, j \in \Gamma$, $i \neq j$, \bm{$n{_i}{_j}$} al n\'umero de enfrentamientos entre $i$ y $j$. Una vez definido esto, a través de una serie de postulados y argumentos matemáticos, el paper \textbf{[1]} plantea que las probabilidades se obtienen como resultado de un sistema de ecuaciones lineales de la forma \bm{$Cr = b$}. \\

Donde:

\begin{itemize}
\item 
$C \in R^{T \times T}, C{_i}{_j} =
\left\{
	\begin{array}{lcc}
		-n{_i}{_j} & si & i \neq j \\
		\\ 2 + n{_i} & si & i = j \\
	\end{array}
\right.$
\item $r \in R^{T}$, donde $r{_i} = $ probabilidad de que el equipo i gane su siguiente partido
\item $b \in R^{T}$, donde $b{_i} = 1 + (w{_i} - l{_i}) / 2$
\end{itemize}

Por lo tanto, lo que se busca despejar son los elementos del vector $r$.

$C$ se denomina la \textbf{matriz de Colley} que particularmente, por lo demostrado en \textbf{[1]}, es \textbf{sim\'etrica} ($A = A{^t}$) y \textbf{definida positiva} ($\forall x \neq 0, x^{t}Ax > 0$).

Para resolver este sistema, usaremos dos algoritmos distintos para obtener sistemas de f\'acil resoluci\'on: \textit{Eliminaci\'on Gaussiana} y \textit{Factorizaci\'on de Cholesky}.

\subsubsection{Eliminaci\'on Gaussiana}

La eliminaci\'on gaussiana es un algoritmo que transforma un sistema de ecuaciones en un sistema equivalente, con la caracter\'istica de que este nuevo sistema es triangular superior.

Esto se logra a través de operaciones que no alteran el conjunto solución de un sistema:

\begin{itemize}
\item Multiplicar una ecuación por un escalar
\item Intercambiar ecuaciones
\item Sumar a una ecuación con un múltiplo de otra
\end{itemize}

Se aplican estas operaciones de tal forma que uno obtenga ``ceros'' debajo de la diagonal de la matriz resultado. Profundizaci\'on acerca de este m\'etodo puede ser encontrada en \textbf{[2]}.

Luego se resuelve y obtenemos el resultado deseado. Sea $A \in R^{nxn}, n \in N$. El sistema $Ax = b$ se transforma en uno equivalente $Ux = b'$, con $U$ una matriz triangular superior. \\

Los $x{_i}$ se obtienen de la siguiente manera: \\

$x{_i} = (b'{_i} - \sum\limits_{j = i + 1}^n u_{ij}x_{i}) / u_{ii}$, que es la técnica conocida como \textit{back-substitution}. \\

Se puede observar que si $\exists \, i \in \{1, ..., n\} / a_{ii} = 0$ entonces no se puede realizar este procedimiento. De todas formas, para las matrices \textit{sim\'etricas} y \textit{definidas positivas} se puede probar que se puede realizar la eliminaci\'on sin pivoteos y obtener la $U$ sin problemas.

La combinaci\'on de la Eliminaci\'on Gaussiana y el proceso de \textit{back-substitution} nos deja una complejidad temporal de $O(n^{3})$, ya que es $O(n^{3})$ por parte de la Eliminaci\'on y $O(n^{2})$ en el siguiente y \'ultimo procedimiento. Hay que considerar tambi\'en la cantidad de operaciones en punto flotante que se hacen debido a la aritm\'etica que conlleva. M\'as sobre esto posteriormente.

\subsubsection{Factorizaci\'on de Cholesky} \label{intro_cholesky}

La factorizaci\'on de Cholesky es un caso particular de una factorizaci\'on LU, con L matriz triangular inferior y U matriz triangular superior. Siendo $C \in R^{n \times n}$, $n$ natural, bajo la hip\'otesis de que $A$ sea \textit{sim\'etrica} y \textit{definida positiva}, podemos afirmar que existe una factorizaci\'on de la forma LU de C, tal que $U = L{^t}$ y tal que vale que $\displaystyle\mathop{\forall}_{1 < i < n}$ $L_{ii} > 0$.

Donde, la matriz $A = LL^{t}$ se forma bajo las siguientes ecuaciones: \\

$LL{^t}{_i}{_j} =
\left\{
	\begin{array}{lcc}
		\sqrt{C{_i}{_i} - \sum\limits_{k=1}^{i-1} L{_i}{_k}^2} & si & i = j \\
		\\ \frac{1}{L{_i}{_i}}(C{_i}{_j} - \sum\limits_{k=1}^{i-1} L{_i}{_k}L{^t}{_j}{_k}) & si & i \neq j \\
	\end{array}
\right.$ \\

Luego, el sistema equivalente ser\'a $LL{^t}x = b$, entonces podemos resolver $Ly = b$ por forward-substitution y luego $L{^t}x = y$ para obtener el resultado deseado por back-substitution.

Si bien la complejidad del mismo es $O(n^{3})$, la cantidad de \textit{flops} es mucho menor. Uno estar\'ia tentado a argumentar que este algoritmo es pesado por el calculo utilizando ra\'ices cuadradas. Vamos a comprobar m\'as adelante que esto es falso y el algoritmo de Cholesky posee una constante \textit{oculta} (oculta por la notaci\'on $O$) mucho menor que su contraparte Gaussiana.

Adem\'as de ello, se puede notar que la factorizaci\'on \textit{no} involucra al vector $b$, por ende uno podr\'ia reutilizar los resultados obtenidos, pagando una sola vez el costo c\'ubico, y luego realizando c\'alculos del orden $O(n^{2})$, para resolver infinidades de sistemas en costo cuadr\'atico.
